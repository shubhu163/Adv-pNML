{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7140196,"sourceType":"datasetVersion","datasetId":4120982},{"sourceId":7142119,"sourceType":"datasetVersion","datasetId":4122311},{"sourceId":7142268,"sourceType":"datasetVersion","datasetId":4122410},{"sourceId":7149259,"sourceType":"datasetVersion","datasetId":4127586}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.init as init\nimport torch.nn.functional as F\n\n\nimport sys\nimport numpy as np\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=True)\n\ndef conv_init(m):\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        init.xavier_uniform_(m.weight, gain=np.sqrt(2))\n        init.constant_(m.bias, 0)\n    elif classname.find('BatchNorm') != -1:\n        init.constant_(m.weight, 1)\n        init.constant_(m.bias, 0)\n\nclass wide_basic(nn.Module):\n    def __init__(self, in_planes, planes, dropout_rate, stride=1):\n        super(wide_basic, self).__init__()\n        self.bn1 = nn.BatchNorm2d(in_planes)\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, padding=1, bias=True)\n        self.dropout = nn.Dropout(p=dropout_rate)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=True)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=True),\n            )\n\n    def forward(self, x):\n        out = self.dropout(self.conv1(F.relu(self.bn1(x))))\n        out = self.conv2(F.relu(self.bn2(out)))\n        out += self.shortcut(x)\n\n        return out\n\nclass Wide_ResNet(nn.Module):\n    def __init__(self, depth, widen_factor, dropout_rate, num_classes):\n        super(Wide_ResNet, self).__init__()\n        self.in_planes = 16\n\n        assert ((depth-4)%6 ==0), 'Wide-resnet depth should be 6n+4'\n        n = (depth-4)/6\n        k = widen_factor\n\n        print('| Wide-Resnet %dx%d' %(depth, k))\n        nStages = [16, 16*k, 32*k, 64*k]\n\n        self.conv1 = conv3x3(1,nStages[0])#3\n        self.layer1 = self._wide_layer(wide_basic, nStages[1], n, dropout_rate, stride=1)\n        self.layer2 = self._wide_layer(wide_basic, nStages[2], n, dropout_rate, stride=2)\n        self.layer3 = self._wide_layer(wide_basic, nStages[3], n, dropout_rate, stride=2)\n        self.bn1 = nn.BatchNorm2d(nStages[3], momentum=0.9)\n        self.linear = nn.Linear(nStages[3], num_classes)\n\n    def _wide_layer(self, block, planes, num_blocks, dropout_rate, stride):\n        strides = [stride] + [1]*(int(num_blocks)-1)\n        layers = []\n\n        for stride in strides:\n            layers.append(block(self.in_planes, planes, dropout_rate, stride))\n            self.in_planes = planes\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = self.conv1(x)\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = F.relu(self.bn1(out))\n        out = F.avg_pool2d(out, 4)#8\n        out = out.view(out.size(0), -1)\n        out = self.linear(out)\n\n        return out","metadata":{"execution":{"iopub.status.busy":"2023-12-12T20:06:04.530553Z","iopub.execute_input":"2023-12-12T20:06:04.530974Z","iopub.status.idle":"2023-12-12T20:06:09.633716Z","shell.execute_reply.started":"2023-12-12T20:06:04.530945Z","shell.execute_reply":"2023-12-12T20:06:09.632861Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass PreActBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(PreActBlock, self).__init__()\n        self.bn1 = nn.BatchNorm2d(in_planes)\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n\n        if stride != 1 or in_planes != self.expansion*planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False)\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(x))\n        shortcut = self.shortcut(out) if hasattr(self, 'shortcut') else x\n        out = self.conv1(out)\n        out = self.conv2(F.relu(self.bn2(out)))\n        out += shortcut\n        return out\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(BasicBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != self.expansion*planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(self.expansion*planes)\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        out += self.shortcut(x)\n        out = F.relu(out)\n        return out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != self.expansion*planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(self.expansion*planes)\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = F.relu(self.bn2(self.conv2(out)))\n        out = self.bn3(self.conv3(out))\n        out += self.shortcut(x)\n        out = F.relu(out)\n        return out\n\n\nclass ResNet(nn.Module):\n    def __init__(self, block, num_blocks, num_classes=10):\n        super(ResNet, self).__init__()\n        self.in_planes = 64\n\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n        self.linear = nn.Linear(512*block.expansion, num_classes)\n\n    def _make_layer(self, block, planes, num_blocks, stride):\n        strides = [stride] + [1]*(num_blocks-1)\n        layers = []\n        for stride in strides:\n            layers.append(block(self.in_planes, planes, stride))\n            self.in_planes = planes * block.expansion\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        out = F.avg_pool2d(out, 4)\n        out = out.view(out.size(0), -1)\n        out = self.linear(out)\n        return out\n\n\ndef PreActResNet18():\n    return ResNet(PreActBlock, [2,2,2,2])\n\ndef ResNet18():\n    return ResNet(BasicBlock, [2,2,2,2])\n\n# Instantiate the ResNet model\n# model = ResNet(BasicBlock, [3, 4, 6, 3])","metadata":{"execution":{"iopub.status.busy":"2023-12-12T20:06:14.088830Z","iopub.execute_input":"2023-12-12T20:06:14.089255Z","iopub.status.idle":"2023-12-12T20:06:14.119825Z","shell.execute_reply.started":"2023-12-12T20:06:14.089228Z","shell.execute_reply":"2023-12-12T20:06:14.118669Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nimport torch\nfrom torch.utils.data import DataLoader\nfrom torchvision import models, datasets, transforms\nimport torchvision.transforms as transforms\nimport matplotlib.pyplot as plt\nfrom torch.optim.lr_scheduler import StepLR\nimport random\nimport numpy as np\nseed =42\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","metadata":{"execution":{"iopub.status.busy":"2023-12-12T20:06:17.859749Z","iopub.execute_input":"2023-12-12T20:06:17.860188Z","iopub.status.idle":"2023-12-12T20:06:18.544919Z","shell.execute_reply.started":"2023-12-12T20:06:17.860156Z","shell.execute_reply":"2023-12-12T20:06:18.544092Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"transform_train = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomCrop(32, padding=4),\n    transforms.ToTensor(),\n])\n\ntransform_test = transforms.Compose([\n    transforms.ToTensor(),\n])\n\n# Load CIFAR-10 dataset\ntrainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\ntrainloader = DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\ntestset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\ntestloader = DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-12T20:06:27.674818Z","iopub.execute_input":"2023-12-12T20:06:27.675198Z","iopub.status.idle":"2023-12-12T20:06:34.167589Z","shell.execute_reply.started":"2023-12-12T20:06:27.675168Z","shell.execute_reply":"2023-12-12T20:06:34.166563Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 170498071/170498071 [00:03<00:00, 56388582.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/cifar-10-python.tar.gz to ./data\nFiles already downloaded and verified\n","output_type":"stream"}]},{"cell_type":"code","source":"transform1 = transforms.Compose([transforms.RandomRotation(degrees = 10),\n                                transforms.RandomHorizontalFlip(0.5),\n                                transforms.ToTensor()])\n\ntrainset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform1, download=True)\ntestset = torchvision.datasets.MNIST(root='./data', train=False, transform=transform1, download=True)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-12-07T18:06:16.104353Z","iopub.execute_input":"2023-12-07T18:06:16.104765Z","iopub.status.idle":"2023-12-07T18:06:17.040821Z","shell.execute_reply.started":"2023-12-07T18:06:16.104723Z","shell.execute_reply":"2023-12-07T18:06:17.039966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport matplotlib.pyplot as plt\ndef pgd_attack(x, y, model, niter=10, eps=0.07,stepsize=8/255,random_init=True):\n    \"\"\"\n    PGD attack.\n\n    Arguments:\n        model (nn.Module): The model to attack.\n        images (torch.Tensor): Input images to be perturbed.\n        labels (torch.Tensor): True labels for the input images.\n        eps (float): Maximum perturbation (default: 8/255).\n        alpha (float): Step size (default: 2/255).\n        steps (int): Number of steps (default: 10).\n        random_start (bool): Use random initialization of delta (default: True).\n        targeted (bool): Perform a targeted attack (default: False).\n\n    Returns:\n        torch.Tensor: Adversarial images.\n\n    \"\"\"\n    device = x.device\n    x = x.clone().detach().to(device)\n    y = torch.tensor([y])\n    y = y.clone().detach().to(device)\n    loss = nn.CrossEntropyLoss()\n    adv_x = x.clone().detach()\n\n    if random_init:\n        # Starting at a uniformly random point\n        adv_x = adv_x + torch.empty_like(adv_x).uniform_(-eps, eps)\n        adv_x = torch.clamp(adv_x, min=0, max=1).detach()\n\n    for i in range(niter):\n        adv_x.requires_grad = True\n        outputs = model(adv_x)\n        cost = loss(outputs,y)\n\n        # Update adversarial images\n        grad = torch.autograd.grad(cost, adv_x, retain_graph=False, create_graph=False)[0]\n\n        adv_x = adv_x.detach() + stepsize * grad.sign()\n        delta = torch.clamp(adv_x - x, min=-eps, max=eps)\n        adv_x = torch.clamp(x + delta, min=0, max=1).detach()\n\n    return adv_x","metadata":{"execution":{"iopub.status.busy":"2023-12-12T20:06:34.876649Z","iopub.execute_input":"2023-12-12T20:06:34.877360Z","iopub.status.idle":"2023-12-12T20:06:34.887591Z","shell.execute_reply.started":"2023-12-12T20:06:34.877325Z","shell.execute_reply":"2023-12-12T20:06:34.886742Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nfrom torchvision.models import resnet50\n\n# Check if GPU is available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n\n\n# Load your trained ResNet-50 model\nresnet50_model = torch.load('/kaggle/input/resnet-file/RESNET18_CIFAR_70EPOCHS(1).pt')\n\n\n# Function to perform x refinement\ndef xrefine(x, yi, model, l):\n    x.requires_grad = True\n    x = x.to(device)  # Move to GPU\n    output = model(x)\n    loss = output[0, yi]  # Target label loss\n    model.zero_grad()\n    loss.backward()\n\n    with torch.no_grad():\n        x_grad = x.grad.sign()\n        refined_x = x - l * x_grad\n    return refined_x\n\n# Function to generate adversarial pNML labels\ndef generate_adversarial_pnml_labels(x,y, model, labels, l):\n    adv_labels = []\n    x = x.unsqueeze(0).to(device) # Add batch dimension and move to GPU\n    for yi in labels:\n        refined_x = xrefine(x, yi, model, l)\n        refined_x = refined_x.to(device)  # Move to GPU\n        adv_pgd_sample = pgd_attack(refined_x,yi,model)\n        output = model(adv_pgd_sample)\n        probability = torch.softmax(output, dim=1)[0, yi].item()\n        adv_labels.append(probability)\n    return adv_labels\n\n# Calculate clean accuracy\ncorrect = 0\ntotal = 0\n\nfor i in range(len(testset)):\n    #if i >= 100:\n        #break\n    x, y = testset[i]\n    labels = list(range(10))  # MNIST labels\n\n    # Generate adversarial pNML labels\n    adv_pnml_labels = generate_adversarial_pnml_labels(x,y, resnet50_model, labels, l=0.02)\n\n    predicted_label = adv_pnml_labels.index(max(adv_pnml_labels))\n    if predicted_label == y:\n        correct += 1\n\n    total += 1\n\nclean_accuracy = correct / total\nprint(\"Clean accuracy:\", clean_accuracy)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fgsm_attack(data, epsilon, input_grad):\n    perturbed_data = data + epsilon * input_grad.sign()\n    perturbed_data = torch.clamp(perturbed_data, 0, 1)  # Clip to maintain pixel range [0, 1]\n    return perturbed_data\n\ndef generate_adversarial_examples(model, data, target, epsilon):\n    data = data.to(device).requires_grad_()\n    target = torch.tensor([target]).to(device)\n    output = model(data)\n    criterion = nn.CrossEntropyLoss()\n    loss = criterion(output, target)\n    model.zero_grad()\n    loss.backward()\n    input_grad = data.grad.data\n    perturbed_data = fgsm_attack(data, epsilon, input_grad)\n    return perturbed_data","metadata":{"execution":{"iopub.status.busy":"2023-12-07T19:33:22.268692Z","iopub.execute_input":"2023-12-07T19:33:22.269085Z","iopub.status.idle":"2023-12-07T19:33:22.276141Z","shell.execute_reply.started":"2023-12-07T19:33:22.269055Z","shell.execute_reply":"2023-12-07T19:33:22.275082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# FGSM","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nfrom torchvision.models import resnet50\n\n# Check if GPU is available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n\n\n# Load your trained ResNet-50 model\nresnet50_model = torch.load('/kaggle/input/resnet-file/RESNET18_CIFAR_70EPOCHS(1).pt')\n\n\n# Function to perform x refinement\ndef xrefine(x, yi, model, l):\n    x.requires_grad = True\n    x = x.to(device)  # Move to GPU\n    output = model(x)\n    loss = output[0, yi]  # Target label loss\n    model.zero_grad()\n    loss.backward()\n\n    with torch.no_grad():\n        x_grad = x.grad.sign()\n        refined_x = x - l * x_grad\n    return refined_x\n\n# Function to generate adversarial pNML labels\ndef generate_adversarial_pnml_labels(x,y, model, labels, l):\n    adv_labels = []\n    x = x.unsqueeze(0).to(device) # Add batch dimension and move to GPU\n    for yi in labels:\n        refined_x = xrefine(x, yi, model, l)\n        refined_x = refined_x.to(device)  # Move to GPU\n        adv_pgd_sample = generate_adversarial_examples(model,refined_x,yi,0.03)\n        output = model(refined_x)\n        probability = torch.softmax(output, dim=1)[0, yi].item()\n        adv_labels.append(probability)\n    return adv_labels\n\n# Calculate clean accuracy\ncorrect = 0\ntotal = 0\n\nfor i in range(len(testset)):\n    if i >= 100:\n        break\n    x, y = testset[i]\n    labels = list(range(10))  # MNIST labels\n\n    # Generate adversarial pNML labels\n    adv_pnml_labels = generate_adversarial_pnml_labels(x,y, resnet50_model, labels, l=0.1)\n\n    predicted_label = adv_pnml_labels.index(max(adv_pnml_labels))\n    if predicted_label == y:\n        correct += 1\n\n    total += 1\n\nclean_accuracy = correct / total\nprint(\"Clean accuracy:\", clean_accuracy)","metadata":{"execution":{"iopub.status.busy":"2023-12-07T19:34:03.053806Z","iopub.execute_input":"2023-12-07T19:34:03.054639Z","iopub.status.idle":"2023-12-07T19:34:19.395145Z","shell.execute_reply.started":"2023-12-07T19:34:03.054603Z","shell.execute_reply":"2023-12-07T19:34:19.394272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# PGD attack function\ndef pgd_attack(x, y, model, niter=10, eps=0.1, stepsize=0.01, random_init=True):\n    device = x.device\n    x = x.clone().detach().to(device)\n    y = torch.tensor([y]).to(device)  # Convert label y to tensor and move to device\n    loss = nn.CrossEntropyLoss()\n    adv_x = x.clone().detach()\n\n    if random_init:\n        adv_x = adv_x + eps * torch.randn_like(adv_x).to(device).detach().sign()\n        adv_x = torch.clamp(adv_x, min=0, max=1)\n\n    for _ in range(niter):\n        adv_x.requires_grad = True\n        output = model(adv_x)\n        model.zero_grad()\n        adv_loss = loss(output, y)\n        adv_loss.backward()\n\n        # PGD step\n        adv_x = adv_x + stepsize * adv_x.grad.detach().sign()\n        eta = torch.clamp(adv_x - x, min=-eps, max=eps)\n        adv_x = torch.clamp(x + eta, min=0, max=1).detach()\n\n    return adv_x\n\n# Example usage:\n# x is the clean image, y is the true label, model is your ResNet-50 model\n# niter is the number of PGD iterations, eps is the epsilon value, stepsize is the step size for PGD attack\n\n# adv_pgd_sample = pgd_attack(x, y, resnet50_model, niter=20, eps=0.1, stepsize=0.01, random_init=True)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-07T01:50:34.099149Z","iopub.execute_input":"2023-12-07T01:50:34.099545Z","iopub.status.idle":"2023-12-07T01:50:34.109001Z","shell.execute_reply.started":"2023-12-07T01:50:34.099515Z","shell.execute_reply":"2023-12-07T01:50:34.107986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def xrefine(x, yi, model, l):\n    x.requires_grad = True\n    x = x.to(device)  # Move to GPU\n    output = model(x)\n    loss = output[0, yi]  # Target label loss\n    model.zero_grad()\n    loss.backward()\n\n    with torch.no_grad():\n        x_grad = x.grad.sign()\n        refined_x = x - l * x_grad\n    return refined_x","metadata":{"execution":{"iopub.status.busy":"2023-12-07T01:50:36.856652Z","iopub.execute_input":"2023-12-07T01:50:36.857035Z","iopub.status.idle":"2023-12-07T01:50:36.865798Z","shell.execute_reply.started":"2023-12-07T01:50:36.857003Z","shell.execute_reply":"2023-12-07T01:50:36.864544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_adversarial_pnml_labels_with_pgd(x, model, labels, l, pgd_eps, pgd_iters, pgd_step):\n    adv_labels = []\n    x = x.unsqueeze(0).to(device)  # Add batch dimension and move to GPU\n    for yi in labels:\n        refined_x = xrefine(x, yi, model, l)\n        refined_x = refined_x.to(device)  # Move to GPU\n        \n        # PGD attack on the refined sample\n        adv_pgd_sample = pgd_attack(refined_x, yi, model, pgd_iters, pgd_eps, pgd_step)\n        \n        # Get the model output for the PGD-adversarial sample\n        output = model(adv_pgd_sample)\n        \n        # Calculate probability for the specific label yi\n        probability = torch.softmax(output, dim=1)[0, yi].item()\n        adv_labels.append(probability)\n    return adv_labels","metadata":{"execution":{"iopub.status.busy":"2023-12-07T01:50:39.418946Z","iopub.execute_input":"2023-12-07T01:50:39.419590Z","iopub.status.idle":"2023-12-07T01:50:39.425813Z","shell.execute_reply.started":"2023-12-07T01:50:39.419557Z","shell.execute_reply":"2023-12-07T01:50:39.425046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"adv_correct = 0\ntotal = 0\nresnet50_model = torch.load('/kaggle/input/resnett/Resnet50_Mnist_10_Adv2_pt (1)')\nresnet50_model.to(device)\nresnet50_model.eval()\n\n\nfor i in range(len(testset)):\n    if i >= 100:\n        break\n    x, y = testset[i]\n    labels = list(range(10))  # MNIST labels\n    # Generate adversarial pNML labels\n    adv_pnml_labels = generate_adversarial_pnml_labels_with_pgd(x, resnet50_model, labels, l=0.1, pgd_eps=0.3, pgd_iters=10, pgd_step=2/255)\n\n    # Get the predicted label based on the adversarial pNML labels\n    predicted_label = adv_pnml_labels.index(max(adv_pnml_labels))\n    if predicted_label == y:\n        adv_correct += 1\n\n    total += 1\n\nadversarial_accuracy = adv_correct / total\nprint(\"Adversarial accuracy of pNML:\", adversarial_accuracy)","metadata":{"execution":{"iopub.status.busy":"2023-12-07T01:52:05.335377Z","iopub.execute_input":"2023-12-07T01:52:05.335971Z","iopub.status.idle":"2023-12-07T01:55:03.791347Z","shell.execute_reply.started":"2023-12-07T01:52:05.335940Z","shell.execute_reply":"2023-12-07T01:55:03.790320Z"},"trusted":true},"execution_count":null,"outputs":[]}]}